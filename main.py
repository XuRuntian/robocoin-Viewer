# main.py
import sys
import os
import argparse
import time
from pathlib import Path

# ç¡®ä¿èƒ½æ‰¾åˆ° src
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from src.core.inspector import DatasetInspector
from src.core.factory import ReaderFactory
from src.core.reviewer import DatasetReviewer
from src.core.config_generator import ConfigGenerator
from src.core.organizer import DatasetOrganizer
from src.ui.rerun_visualizer import RerunVisualizer
import rerun as rr
import rerun.blueprint as rrb

def setup_comparison_layout(sample_names, cameras):
    """
    é…ç½®å¹¶æ’å¯¹æ¯”è§†å›¾çš„è“å›¾
    """
    columns = []
    for idx, name in enumerate(sample_names):
        cam_views = []
        for cam in cameras:
            cam_views.append(rrb.Spatial2DView(
                origin=f"preview/sample_{idx}/{cam}",
                name=f"{cam}"
            ))
        columns.append(rrb.Vertical(
            rrb.TextDocumentView(origin=f"preview/sample_{idx}/info", name=f"{name}"),
            *cam_views,
            name=f"Sample {idx+1}"
        ))
    
    blueprint = rrb.Blueprint(rrb.Horizontal(*columns), collapse_panels=True)
    rr.send_blueprint(blueprint)

def save_report(root_dir, bad_datasets):
    import datetime
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(root_dir, f"cleaning_report_{timestamp}.txt")
    try:
        with open(path, "w") as f:
            f.write("# Bad Datasets Report\n")
            for p in bad_datasets: f.write(f"{p}\n")
        print(f"ğŸ“„ å¼‚å¸¸æŠ¥å‘Šå·²ä¿å­˜: {path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    # 1. å‘½ä»¤è¡Œå‚æ•°å®šä¹‰
    parser = argparse.ArgumentParser(description="RoboCoin Viewer - å…·èº«æ™ºèƒ½æ•°æ®é›†æ¸…æ´—ä¸é¢„è§ˆå·¥å…·")
    parser.add_argument("path", type=str, help="æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„ (ä¾‹å¦‚: ./data/hdf5)")
    parser.add_argument("--skip-review", action="store_true", help="è·³è¿‡ã€äº¤äº’å¼å®¡æ ¸ã€‘æ­¥éª¤ï¼Œç›´æ¥é¢„è§ˆ")
    parser.add_argument("--no-preview", action="store_true", help="æµç¨‹ç»“æŸåä¸æ’­æ”¾é¢„è§ˆè§†é¢‘")
    
    args = parser.parse_args()
    TARGET_DIR = args.path
    
    if not os.path.exists(TARGET_DIR):
        print(f"âŒ é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨ -> {TARGET_DIR}")
        return

    # åˆå§‹åŒ– Rerun åº”ç”¨
    viz = RerunVisualizer("RoboCoin_Main")

    # === STEP 1: æ ¼å¼æ£€æŸ¥ (Inspector) ===
    print("\nğŸ” [1/4] æ­£åœ¨æ‰«æç›®å½•æ ¼å¼...")
    inspector = DatasetInspector(TARGET_DIR)
    inspector.scan()
    
    # å¦‚æœä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ï¼Œç›´æ¥é€€å‡º
    if not inspector.check_consistency():
        return 

    # åˆå§‹åŒ– Organizer
    organizer = DatasetOrganizer(TARGET_DIR)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ•´ç†
    grouped_datasets = inspector.grouped_datasets
    if len(grouped_datasets) > 1:
        print(f"ğŸ”„ æ£€æµ‹åˆ°å¤šç§ç±»å‹æ•°æ®é›†: {list(grouped_datasets.keys())}")
        new_grouped_paths = organizer.sort_by_type(grouped_datasets, TARGET_DIR)
        # æ›´æ–°æœ‰æ•ˆè·¯å¾„ä¸ºæ•´ç†åçš„æ–°è·¯å¾„
        valid_paths = []
        for paths in new_grouped_paths.values():
            valid_paths.extend(paths)
        print(f"âœ… æ•°æ®é›†å·²æ•´ç†åˆ°ç±»å‹åˆ†ç»„æ–‡ä»¶å¤¹ä¸­")
    else:
        valid_paths = inspector.get_all_valid_paths()
        
    print(f"âœ… æœ‰æ•ˆæ•°æ®é›†: {len(valid_paths)} æ¡")

    # === STEP 2: äº¤äº’å®¡æ ¸ (Reviewer) ===
    final_paths = valid_paths
    
    if not args.skip_review:
        # å¯åŠ¨å®¡æ ¸å™¨ (é”®ç›˜æ§åˆ¶: N/P/Space/Esc)
        reviewer = DatasetReviewer(viz)
        bad_datasets = reviewer.start_review(valid_paths)
        
        if bad_datasets:
            # ä½¿ç”¨ Organizer è¿›è¡Œç‰©ç†éš”ç¦»
            quarantine_dir = organizer.quarantine_bad_data(bad_datasets, TARGET_DIR)
            print(f"ğŸ”’ å¼‚å¸¸æ•°æ®å·²éš”ç¦»åˆ°: {quarantine_dir}")
            # å‰”é™¤åæ•°æ®ï¼Œä¿ç•™å¥½æ•°æ®è¿›å…¥ä¸‹ä¸€æ­¥
            final_paths = [p for p in valid_paths if p not in bad_datasets]
            print(f"ğŸ§¹ å‰”é™¤å¼‚å¸¸æ•°æ®åå‰©ä½™: {len(final_paths)} æ¡")
        else:
            print("âœ¨ å®Œç¾ï¼æœªå‘ç°å¼‚å¸¸æ•°æ®ã€‚")
    else:
        print("â© å·²è·³è¿‡äº¤äº’å®¡æ ¸æ­¥éª¤ã€‚")

    if not final_paths:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ä¾›åç»­å¤„ç†ã€‚")
        return

    # === STEP 3: å¹¶è¡Œé¢„è§ˆ (Preview) ===
    if not args.no_preview:
        # è‡ªåŠ¨é€‰å– 3 ä¸ªæ ·æœ¬ (é¦–ã€ä¸­ã€å°¾)
        indices = [0]
        if len(final_paths) > 1: indices.append(len(final_paths)-1)
        if len(final_paths) > 2: indices.insert(1, len(final_paths)//2)
        sample_paths = [final_paths[i] for i in indices]
        
        # å‡†å¤‡å…ƒæ•°æ® (è·å–ç›¸æœºåˆ—è¡¨)
        temp_reader = ReaderFactory.get_reader(sample_paths[0])
        temp_reader.load(sample_paths[0])
        cameras = temp_reader.get_all_sensors()
        
        print("\nğŸ“º [3/4] æ­£åœ¨å‡†å¤‡å¹¶è¡Œé¢„è§ˆ...")
        setup_comparison_layout([os.path.basename(p) for p in sample_paths], cameras)
        temp_reader.close()
        
        # æ¸…ç†æ—§ç”»é¢
        rr.log("preview", rr.Clear(recursive=True))
        rr.log("world", rr.Clear(recursive=True))
        
        # é¢„åŠ è½½æ‰€æœ‰ reader å¹¶è®¡ç®—æœ€å¤§é•¿åº¦
        readers = []
        max_len = 0
        print("ğŸ“¥ æ­£åœ¨ç¼“å†²è§†é¢‘æµ...")
        for p in sample_paths:
            r = ReaderFactory.get_reader(p)
            r.load(p)
            readers.append(r)
            if r.get_length() > max_len: max_len = r.get_length()
        
        print(f"â–¶ï¸ æ­£åœ¨åŒæ­¥æ’­æ”¾ {len(readers)} ä¸ªæ ·æœ¬ (Max Frames: {max_len})...")
        
        # æ’­æ”¾å¾ªç¯
        for i in range(max_len):
            rr.set_time_sequence("frame_idx", i)
            
            for s_idx, r in enumerate(readers):
                if i >= r.get_length(): continue
                
                frame = r.get_frame(i)
                # Log å›¾åƒ
                for cam, img in frame.images.items():
                    rr.log(f"preview/sample_{s_idx}/{cam}", rr.Image(img))
                
                # Log æ ‡é¢˜ (ä»…ç¬¬0å¸§)
                if i == 0:
                    rr.log(f"preview/sample_{s_idx}/info", rr.TextDocument(f"### {os.path.basename(sample_paths[s_idx])}"))

            # ç®€å•çš„è¿›åº¦æ‰“å°
            if i % 30 == 0: print(".", end="", flush=True)

        for r in readers: r.close()
        print("\nâœ… é¢„è§ˆæ’­æ”¾å®Œæˆã€‚")

    # === STEP 4: ç”Ÿæˆé…ç½® (ConfigGenerator) ===
    print("\nğŸ“ [4/4] æ£€æŸ¥é…ç½®ç”Ÿæˆæ¥å£...")
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬æ¥è°ƒç”¨æ¥å£
    sample_reader = ReaderFactory.get_reader(final_paths[0])
    sample_reader.load(final_paths[0])
    
    # è¿™é‡Œè°ƒç”¨æˆ‘ä»¬åˆšå†™çš„â€œç©ºæ¥å£â€
    ConfigGenerator.analyze_and_save(sample_reader, TARGET_DIR)
    sample_reader.close()

    print("\nğŸ‰ å…¨éƒ¨æµç¨‹ç»“æŸï¼")

if __name__ == "__main__":
    main()
