# tests/test_pipeline.py
import sys
import os
import time
import datetime # <--- æ–°å¢æ—¶é—´åº“

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.core.inspector import DatasetInspector
from src.core.factory import ReaderFactory
from src.core.reviewer import DatasetReviewer
from src.ui.rerun_visualizer import RerunVisualizer
import rerun as rr

def save_report(root_dir, bad_datasets):
    """
    å°†å¼‚å¸¸æ•°æ®åˆ—è¡¨ä¿å­˜åˆ°æ–‡ä»¶
    """
    if not bad_datasets:
        return None

    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶åï¼Œé˜²æ­¢è¦†ç›–
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    report_filename = f"cleaning_report_{timestamp}.txt"
    report_path = os.path.join(root_dir, report_filename)

    try:
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(f"# Robocoin Data Cleaning Report\n")
            f.write(f"# Date: {datetime.datetime.now()}\n")
            f.write(f"# Total Bad Datasets: {len(bad_datasets)}\n")
            f.write("-" * 50 + "\n")
            for path in bad_datasets:
                f.write(f"{path}\n")
        
        print(f"\nğŸ“„ [æŠ¥å‘Šå·²ç”Ÿæˆ]: {report_path}")
        return report_path
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
        return None

def run_pipeline():
    # 1. ç›®æ ‡ç›®å½• (è¯·ä¿®æ”¹ä¸ºä½ çœŸå®çš„æµ‹è¯•è·¯å¾„)
    TARGET_DIR = "/home/user/test_data/hdf5"
    
    # åˆå§‹åŒ– Rerun (åªéœ€ä¸€æ¬¡)
    viz = RerunVisualizer("RoboCoin_Pipeline_Final")

    # === STEP 1: æ ¼å¼ä¸€è‡´æ€§æ£€æŸ¥ (Gatekeeper) ===
    print("\n[STEP 1] æ ¼å¼æ£€æŸ¥...")
    inspector = DatasetInspector(TARGET_DIR)
    inspector.scan()
    
    if not inspector.check_consistency():
        print("\nâ›” æµç¨‹ç»ˆæ­¢ï¼šè¯·å…ˆæ¸…ç†æ•°æ®é›†ä¸­çš„å¼‚å¸¸æ–‡ä»¶ã€‚")
        return

    # è·å–æ‰€æœ‰é€šè¿‡åˆç­›çš„è·¯å¾„
    valid_paths = inspector.get_all_valid_paths()
    print(f"âœ… å¾…å®¡æ ¸æ•°æ®: {len(valid_paths)} æ¡")

    # === STEP 2: äº¤äº’å¼å†…å®¹å®¡æ ¸ (Reviewer) ===
    # è¿™é‡Œä¼šé˜»å¡ï¼Œç›´åˆ°ç”¨æˆ·æŒ‰ 'q' æˆ–å®¡æ ¸å®Œæˆ
    reviewer = DatasetReviewer(viz)
    bad_datasets = reviewer.start_review(valid_paths)

    # å‰”é™¤åæ•°æ®
    final_paths = [p for p in valid_paths if p not in bad_datasets]
    
    print("\n" + "="*50)
    print(f"ğŸ‰ å®¡æ ¸å®Œæˆï¼ä¿ç•™ {len(final_paths)} / {len(valid_paths)} æ¡æœ‰æ•ˆæ•°æ®")
    
    # === æ–°å¢åŠŸèƒ½: ä¿å­˜å¼‚å¸¸è®°å½•åˆ°æ–‡ä»¶ ===
    if bad_datasets:
        print(f"ğŸ—‘ï¸ æ£€æµ‹åˆ° {len(bad_datasets)} æ¡å¼‚å¸¸æ•°æ®")
        report_file = save_report(TARGET_DIR, bad_datasets)
        
        if report_file:
            print(f"ğŸ’¡ æç¤º: ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ‰¹é‡åˆ é™¤è¿™äº›æ•°æ®:")
            print(f"   xargs rm -rf < {os.path.basename(report_file)}")
    else:
        print("âœ¨ å®Œç¾ï¼æ²¡æœ‰å‘ç°å¼‚å¸¸æ•°æ®ã€‚")
    print("="*50)

    if not final_paths:
        print("âŒ æ‰€æœ‰æ•°æ®éƒ½è¢«æ ‡è®°ä¸º Badï¼Œæµç¨‹ç»“æŸã€‚")
        return

    # === STEP 3: æœ€ç»ˆé¢„è§ˆ (Preview) ===
    user_input = input("\nâ–¶ï¸ æ˜¯å¦æ’­æ”¾å‡ æ¡æ ·æœ¬æ•°æ®è¿›è¡Œæœ€ç»ˆç¡®è®¤ï¼Ÿ(y/n): ")
    if user_input.lower() == 'y':
        # é€‰å– 3 ä¸ªæ ·æœ¬ (é¦–ã€ä¸­ã€å°¾)
        indices = [0]
        if len(final_paths) > 1: indices.append(len(final_paths)-1)
        if len(final_paths) > 2: indices.insert(1, len(final_paths)//2)
        
        sample_paths = [final_paths[i] for i in indices]
        
        # é‡ç½®å›æ ‡å‡†å¸ƒå±€
        sample_reader = ReaderFactory.get_reader(sample_paths[0])
        sample_reader.load(sample_paths[0])
        viz.setup_layout(sample_reader.get_all_sensors()) 
        sample_reader.close()
        
        print("\næ­£åœ¨ç¼“å†²è§†é¢‘æµ...")
        for idx, path in enumerate(sample_paths):
            reader = ReaderFactory.get_reader(path)
            reader.load(path)
            
            ep_name = os.path.basename(path)
            print(f"æ’­æ”¾: {ep_name}")
            
            # æ’­æ”¾ 150 å¸§
            for i in range(min(150, reader.get_length())):
                frame = reader.get_frame(i)
                viz.log_frame(frame, idx * 1000 + i)
            
            reader.close()

    print("\nâœ… æµç¨‹ç»“æŸã€‚")

if __name__ == "__main__":
    run_pipeline()